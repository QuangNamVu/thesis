{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQRoWTXQBwbD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zr5SP79lC9-2",
    "outputId": "22165e61-9ba2-4935-f3c6-df46b42a7fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p8Eb8ajfCVTD",
    "outputId": "2e56eac1-604d-491c-9e87-fec8089115d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   507918   1015835 105699993 /content/gdrive/My Drive/Colab Notebooks/Data/week2/golden.csv\n"
     ]
    }
   ],
   "source": [
    "!wc /content/gdrive/My\\ Drive/Colab\\ Notebooks/Data/week2/golden.csv\n",
    "# !head -n 100000 /content/gdrive/My\\ Drive/Colab\\ Notebooks/Data/week2/golden.csv > /content/gdrive/My\\ Drive/Colab\\ Notebooks/Data/week7/100000golden.csv\n",
    "# !du -sh /content/gdrive/My\\ Drive/Colab\\ Notebooks/Data/week7/100000golden.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQNx_2iPDRFq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/week2/golden.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "CkQazIW0DUht",
    "outputId": "d3c46ae7-44f3-44b8-ca00-11583e1554f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_(BTC)</th>\n",
       "      <th>Volume_(Currency)</th>\n",
       "      <th>Weighted_Price</th>\n",
       "      <th>Weighted_Price_MA60</th>\n",
       "      <th>WP_MA1_mins</th>\n",
       "      <th>WP_MA5_mins</th>\n",
       "      <th>WP_MA15_mins</th>\n",
       "      <th>WP_MA30_mins</th>\n",
       "      <th>WP_MA60_mins</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>5.079170e+05</td>\n",
       "      <td>507917.000000</td>\n",
       "      <td>507917.000000</td>\n",
       "      <td>507917.000000</td>\n",
       "      <td>507917.000000</td>\n",
       "      <td>507917.000000</td>\n",
       "      <td>507917.000000</td>\n",
       "      <td>507917.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.514748e+09</td>\n",
       "      <td>8.797389e+05</td>\n",
       "      <td>8.805404e+05</td>\n",
       "      <td>8.789189e+05</td>\n",
       "      <td>8.797387e+05</td>\n",
       "      <td>1.296136e+01</td>\n",
       "      <td>1.170516e+07</td>\n",
       "      <td>8.797113e+05</td>\n",
       "      <td>8.796891e+05</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>0.989128</td>\n",
       "      <td>0.978218</td>\n",
       "      <td>0.967537</td>\n",
       "      <td>0.952362</td>\n",
       "      <td>-0.183510</td>\n",
       "      <td>0.481222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.879069e+06</td>\n",
       "      <td>4.387864e+05</td>\n",
       "      <td>4.393738e+05</td>\n",
       "      <td>4.381860e+05</td>\n",
       "      <td>4.387830e+05</td>\n",
       "      <td>1.649170e+01</td>\n",
       "      <td>1.700317e+07</td>\n",
       "      <td>4.387680e+05</td>\n",
       "      <td>4.387485e+05</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.027411</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.051576</td>\n",
       "      <td>1787.577142</td>\n",
       "      <td>0.499648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.499375e+09</td>\n",
       "      <td>2.062910e+05</td>\n",
       "      <td>2.064800e+05</td>\n",
       "      <td>2.060000e+05</td>\n",
       "      <td>2.063460e+05</td>\n",
       "      <td>5.600000e-07</td>\n",
       "      <td>2.274938e-01</td>\n",
       "      <td>2.063754e+05</td>\n",
       "      <td>2.088214e+05</td>\n",
       "      <td>0.897054</td>\n",
       "      <td>0.809287</td>\n",
       "      <td>0.726925</td>\n",
       "      <td>0.693798</td>\n",
       "      <td>0.628358</td>\n",
       "      <td>-80875.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.506993e+09</td>\n",
       "      <td>5.039300e+05</td>\n",
       "      <td>5.041170e+05</td>\n",
       "      <td>5.036990e+05</td>\n",
       "      <td>5.039800e+05</td>\n",
       "      <td>3.160630e+00</td>\n",
       "      <td>2.192749e+06</td>\n",
       "      <td>5.039470e+05</td>\n",
       "      <td>5.038718e+05</td>\n",
       "      <td>0.996452</td>\n",
       "      <td>0.985792</td>\n",
       "      <td>0.969498</td>\n",
       "      <td>0.953987</td>\n",
       "      <td>0.928369</td>\n",
       "      <td>-401.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.514820e+09</td>\n",
       "      <td>8.383290e+05</td>\n",
       "      <td>8.387760e+05</td>\n",
       "      <td>8.379960e+05</td>\n",
       "      <td>8.383540e+05</td>\n",
       "      <td>7.641194e+00</td>\n",
       "      <td>5.961625e+06</td>\n",
       "      <td>8.383088e+05</td>\n",
       "      <td>8.383658e+05</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.995353</td>\n",
       "      <td>0.988112</td>\n",
       "      <td>0.980528</td>\n",
       "      <td>0.969623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.522439e+09</td>\n",
       "      <td>1.047999e+06</td>\n",
       "      <td>1.048886e+06</td>\n",
       "      <td>1.047000e+06</td>\n",
       "      <td>1.047999e+06</td>\n",
       "      <td>1.633734e+01</td>\n",
       "      <td>1.425951e+07</td>\n",
       "      <td>1.047936e+06</td>\n",
       "      <td>1.048183e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999305</td>\n",
       "      <td>0.996872</td>\n",
       "      <td>0.994514</td>\n",
       "      <td>0.990275</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.530058e+09</td>\n",
       "      <td>2.312098e+06</td>\n",
       "      <td>2.312100e+06</td>\n",
       "      <td>2.300290e+06</td>\n",
       "      <td>2.312098e+06</td>\n",
       "      <td>7.574348e+02</td>\n",
       "      <td>6.936638e+08</td>\n",
       "      <td>2.311319e+06</td>\n",
       "      <td>2.273014e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129608.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp          Open          High           Low         Close  \\\n",
       "count  5.079170e+05  5.079170e+05  5.079170e+05  5.079170e+05  5.079170e+05   \n",
       "mean   1.514748e+09  8.797389e+05  8.805404e+05  8.789189e+05  8.797387e+05   \n",
       "std    8.879069e+06  4.387864e+05  4.393738e+05  4.381860e+05  4.387830e+05   \n",
       "min    1.499375e+09  2.062910e+05  2.064800e+05  2.060000e+05  2.063460e+05   \n",
       "25%    1.506993e+09  5.039300e+05  5.041170e+05  5.036990e+05  5.039800e+05   \n",
       "50%    1.514820e+09  8.383290e+05  8.387760e+05  8.379960e+05  8.383540e+05   \n",
       "75%    1.522439e+09  1.047999e+06  1.048886e+06  1.047000e+06  1.047999e+06   \n",
       "max    1.530058e+09  2.312098e+06  2.312100e+06  2.300290e+06  2.312098e+06   \n",
       "\n",
       "       Volume_(BTC)  Volume_(Currency)  Weighted_Price  Weighted_Price_MA60  \\\n",
       "count  5.079170e+05       5.079170e+05    5.079170e+05         5.079170e+05   \n",
       "mean   1.296136e+01       1.170516e+07    8.797113e+05         8.796891e+05   \n",
       "std    1.649170e+01       1.700317e+07    4.387680e+05         4.387485e+05   \n",
       "min    5.600000e-07       2.274938e-01    2.063754e+05         2.088214e+05   \n",
       "25%    3.160630e+00       2.192749e+06    5.039470e+05         5.038718e+05   \n",
       "50%    7.641194e+00       5.961625e+06    8.383088e+05         8.383658e+05   \n",
       "75%    1.633734e+01       1.425951e+07    1.047936e+06         1.048183e+06   \n",
       "max    7.574348e+02       6.936638e+08    2.311319e+06         2.273014e+06   \n",
       "\n",
       "         WP_MA1_mins    WP_MA5_mins   WP_MA15_mins   WP_MA30_mins  \\\n",
       "count  507917.000000  507917.000000  507917.000000  507917.000000   \n",
       "mean        0.996834       0.989128       0.978218       0.967537   \n",
       "std         0.006127       0.016220       0.027411       0.038334   \n",
       "min         0.897054       0.809287       0.726925       0.693798   \n",
       "25%         0.996452       0.985792       0.969498       0.953987   \n",
       "50%         0.999328       0.995353       0.988112       0.980528   \n",
       "75%         1.000000       0.999305       0.996872       0.994514   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "        WP_MA60_mins          Delta         Target  \n",
       "count  507917.000000  507917.000000  507917.000000  \n",
       "mean        0.952362      -0.183510       0.481222  \n",
       "std         0.051576    1787.577142       0.499648  \n",
       "min         0.628358  -80875.000000       0.000000  \n",
       "25%         0.928369    -401.000000       0.000000  \n",
       "50%         0.969623       0.000000       0.000000  \n",
       "75%         0.990275     399.000000       1.000000  \n",
       "max         1.000000  129608.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N0 = 507917\n",
    "N = 507917 - 1000\n",
    "\n",
    "H_i = 100\n",
    "n_attributes = 8\n",
    "N_image = N - (H_i-1) # 507890\n",
    "X_conv2d = True\n",
    "y = df['Target']\n",
    "y_target = np.roll(y, -(H_i -1))[:N_image]\n",
    "\n",
    "# [y_roll] N, to N, 2\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-Cv0wZqXDqDd",
    "outputId": "0e7fb383-90df-4f8c-cd0a-6990470e5888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506818, 100, 8)\n"
     ]
    }
   ],
   "source": [
    "attributes_normalize_mean = ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Weighted_Price']\n",
    "attributes_normalize_log = ['Volume_(BTC)', 'Volume_(Currency)']\n",
    "\n",
    "n_attributes_total = attributes_normalize_mean + attributes_normalize_log\n",
    "\n",
    "X_normalized = pd.DataFrame()\n",
    "\n",
    "# standardize\n",
    "\n",
    "for att in attributes_normalize_mean:\n",
    "\n",
    "    float_array = df[att].values.astype(float)\n",
    "    x_mean = float_array.mean()\n",
    "\n",
    "    std = np.std(float_array)\n",
    "\n",
    "    float_array = (float_array - x_mean) / std\n",
    "    X_normalized[att] = float_array\n",
    "\n",
    "\n",
    "for att in attributes_normalize_log:\n",
    "\n",
    "    float_array = df[att].values.astype(float)\n",
    "    \n",
    "    float_array = np.log(float_array)\n",
    "\n",
    "    x_mean = float_array.mean()\n",
    "\n",
    "    std = np.std(float_array)\n",
    "\n",
    "    float_array = (float_array - x_mean) / std\n",
    "    X_normalized[att] = float_array\n",
    "\n",
    "\n",
    "x_values = X_normalized.values #returns a numpy array\n",
    "\n",
    "\n",
    "X_image = np.empty((N_image, H_i, n_attributes), dtype=float)\n",
    "\n",
    "for idx in range(N_image):\n",
    "    X_image[idx] = x_values[idx:idx+H_i]\n",
    "    \n",
    "\n",
    "print(X_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WpdavNPmNp-v"
   },
   "outputs": [],
   "source": [
    "# if X_conv2d is True and len(X_image.shape) is not 4:\n",
    "#   X_image = np.expand_dims(X_image, axis=3)\n",
    "# X_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "6lX4lQRWEuaK",
    "outputId": "c77f8c92-a531-44e0-ac94-c7649aa01f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 100, 128)          5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 100, 64)           24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6400)              25600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 466,050\n",
      "Trainable params: 452,866\n",
      "Non-trainable params: 13,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# momentum_bn = 1-1024/430000\n",
    "def create_model():\n",
    "  \n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=5, padding='same',\n",
    "                        data_format=\"channels_last\", activation=None, \n",
    "                        batch_input_shape=(None, 100, 8),use_bias=True),\n",
    "    keras.layers.BatchNormalization(axis = -1),\n",
    "      \n",
    "#     keras.layers.BatchNormalization(momentum=momentum_bn, axis= -1),\n",
    "\n",
    "    keras.layers.Activation('elu'),\n",
    "      \n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, padding='same',\n",
    "                        data_format=\"channels_last\", activation=None, \n",
    "                        batch_input_shape=(None, 100, 8),use_bias=True),\n",
    "    keras.layers.BatchNormalization(axis = -1),\n",
    "#     keras.layers.BatchNormalization(momentum=momentum_bn, axis= -1),\n",
    "\n",
    "    keras.layers.Activation('elu'),\n",
    "\n",
    "      \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.BatchNormalization(axis = -1),\n",
    "#     keras.layers.BatchNormalization(momentum=momentum_bn, axis= -1),\n",
    "  \n",
    "\n",
    "    keras.layers.Dense(64, activation='elu', use_bias=True),\n",
    "    \n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "  ])\n",
    "  \n",
    "  model.compile(\n",
    "    #optimizer=tf.train.AdamOptimizer(learning_rate=0.0005, beta1=0.995, beta2=0.9995, epsilon=1e-8),\n",
    "\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.0002),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "obqTZORUMj-8",
    "outputId": "fb39151f-245c-443c-c8f2-01ddb1177d0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test GPU should return '/device:GPU:0'\n",
    "\n",
    "tf.test.gpu_device_name()\n",
    "# !mkdir /content/gdrive/My\\ Drive/checkpoint/training_week10/2conv_batchnormalize_elu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cc2uDvJv034"
   },
   "source": [
    "Load pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "l8XRiMdTsFGx",
    "outputId": "3c5206be-313b-482d-93ca-79714d3a79ac"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6735b54ce499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mlatest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "checkpoint_path = \"/content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# Sort the checkpoints by modification time.\n",
    "checkpoints = pathlib.Path(checkpoint_dir).glob(\"*.index\")\n",
    "model = create_model()\n",
    "\n",
    "checkpoints = sorted(checkpoints, key=lambda cp:cp.stat().st_mtime)\n",
    "checkpoints = [cp.with_suffix('') for cp in checkpoints]\n",
    "latest = str(checkpoints[-1])\n",
    "latest\n",
    "\n",
    "\n",
    "# load pre-trained weights\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "id": "WFz2Eqlg2fp1",
    "outputId": "bb10b066-a0cd-433b-9e73-dfb7bc9cd45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430000 samples, validate on 1024 samples\n",
      "Epoch 1/5\n",
      "  2048/430000 [..............................] - ETA: 30s - loss: 0.5700 - acc: 0.7026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: loadtxt: Empty input file: \"/content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/metrics_eval.txt\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429056/430000 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.6879\n",
      "Epoch 00001: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "430000/430000 [==============================] - 27s 63us/step - loss: 0.5707 - acc: 0.6879 - val_loss: 0.6454 - val_acc: 0.5693\n",
      "Epoch 2/5\n",
      "429056/430000 [============================>.] - ETA: 0s - loss: 0.5441 - acc: 0.7078\n",
      "Epoch 00002: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "430000/430000 [==============================] - 27s 63us/step - loss: 0.5441 - acc: 0.7078 - val_loss: 0.6560 - val_acc: 0.5576\n",
      "Epoch 3/5\n",
      "429056/430000 [============================>.] - ETA: 0s - loss: 0.5320 - acc: 0.7186\n",
      "Epoch 00003: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "430000/430000 [==============================] - 27s 63us/step - loss: 0.5318 - acc: 0.7187 - val_loss: 0.5780 - val_acc: 0.7070\n",
      "Epoch 4/5\n",
      "429056/430000 [============================>.] - ETA: 0s - loss: 0.5359 - acc: 0.7155\n",
      "Epoch 00004: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "430000/430000 [==============================] - 27s 63us/step - loss: 0.5358 - acc: 0.7155 - val_loss: 0.7413 - val_acc: 0.5273\n",
      "Epoch 5/5\n",
      "429056/430000 [============================>.] - ETA: 0s - loss: 0.5169 - acc: 0.7282\n",
      "Epoch 00005: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "430000/430000 [==============================] - 27s 64us/step - loss: 0.5169 - acc: 0.7282 - val_loss: 0.5673 - val_acc: 0.7070\n",
      "1024/1024 [==============================] - 0s 122us/step\n",
      "Time: 2.0 mins 16.0 secs\n",
      "Train on 431024 samples, validate on 1024 samples\n",
      "Epoch 1/5\n",
      "430080/431024 [============================>.] - ETA: 0s - loss: 0.5162 - acc: 0.7300\n",
      "Epoch 00001: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "431024/431024 [==============================] - 27s 64us/step - loss: 0.5162 - acc: 0.7300 - val_loss: 0.7425 - val_acc: 0.5293\n",
      "Epoch 2/5\n",
      "430080/431024 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.7431\n",
      "Epoch 00002: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "431024/431024 [==============================] - 27s 64us/step - loss: 0.4975 - acc: 0.7432 - val_loss: 0.9973 - val_acc: 0.4912\n",
      "Epoch 3/5\n",
      "430080/431024 [============================>.] - ETA: 0s - loss: 0.4853 - acc: 0.7519\n",
      "Epoch 00003: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "431024/431024 [==============================] - 28s 64us/step - loss: 0.4854 - acc: 0.7518 - val_loss: 0.9552 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "430080/431024 [============================>.] - ETA: 0s - loss: 0.4964 - acc: 0.7433\n",
      "Epoch 00004: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "431024/431024 [==============================] - 27s 64us/step - loss: 0.4963 - acc: 0.7434 - val_loss: 0.7034 - val_acc: 0.5449\n",
      "Epoch 5/5\n",
      "430080/431024 [============================>.] - ETA: 0s - loss: 0.4739 - acc: 0.7600\n",
      "Epoch 00005: saving model to /content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/cp.ckpt\n",
      "431024/431024 [==============================] - 27s 64us/step - loss: 0.4738 - acc: 0.7601 - val_loss: 0.5906 - val_acc: 0.7021\n",
      "1024/1024 [==============================] - 0s 126us/step\n",
      "Time: 2.0 mins 17.0 secs\n",
      "Train on 432048 samples, validate on 1024 samples\n",
      "Epoch 1/5\n",
      "425984/432048 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.7688"
     ]
    }
   ],
   "source": [
    "#N = 150000\n",
    "# create pre-trained\n",
    "\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "N = 507000\n",
    "N0 = 430000\n",
    "N_val = 1024\n",
    "N_time_update = 1024\n",
    "N_loop = (N - N0) // N_time_update - 10  ### -10 just make sure\n",
    "\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "metrics_file_save = '/content/gdrive/My Drive/checkpoint/training_week10/2conv_batchnormalize_elu_low_eta/metrics_eval.txt'\n",
    "metrics = np.array([])\n",
    "metrics = np.loadtxt(metrics_file_save, delimiter=',')\n",
    "\n",
    "for each_time in range(N_loop):\n",
    "    t0 = time()\n",
    "\n",
    "    X_train = X_image[:N0 + each_time * N_time_update]\n",
    "    X_val = X_image[N0 + each_time * N_time_update + H_i:\\\n",
    "                    N0 + each_time * N_time_update + N_val + H_i]\n",
    "\n",
    "    y_train = y_target[:N0 + each_time * N_val]\n",
    "    y_val = y_target[N0 + each_time * N_time_update + H_i:\\\n",
    "                    N0 + each_time * N_time_update + N_val + H_i]\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train,\n",
    "              batch_size=1024,epochs=5,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[cp_callback]\n",
    "             )\n",
    "    metric_new = model.evaluate(X_val, y_val)\n",
    "    metric_new = np.expand_dims(np.asarray(metric_new), axis=0)\n",
    "    # reshape if empty\n",
    "    metrics = np.concatenate((metrics.reshape(-1,2), metric_new)) \n",
    "  \n",
    "    t1 = time()\n",
    "    print(\"Time: {} mins {} secs\".format((t1 - t0) // 60, (t1 - t0) % 60 // 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdtrhVVJ6nPi"
   },
   "outputs": [],
   "source": [
    "np.mean(metrics, axis=0)\n",
    "np.savetxt(metrics_file_save, metrics, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hOTgBm4GKhC6",
    "outputId": "b23edb63-b89e-4f5e-f6ae-307d77b45f68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_week10_low_eta.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
