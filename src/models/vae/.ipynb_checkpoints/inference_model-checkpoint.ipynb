{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = './train_log/train/model-15'\n",
    "checkpoint_path = '/home/nam/Dropbox/thesis/src/models/vae/train_log/train/checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV is built with OpenMP support. This usually results in poor performance. For details, see https://github.com/tensorpack/benchmarks/blob/master/ImageNet/benchmark-opencv-resize.py\n"
     ]
    }
   ],
   "source": [
    "import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpack.predict.config import PredictConfig\n",
    "from tensorpack.tfutils import SmartInit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAE.Model import ModelDesc, Trainer  # , RandomZData\n",
    "from VAE import get_default_hparams\n",
    "\n",
    "hps = get_default_hparams()\n",
    "M = ModelDesc(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_config = PredictConfig(\n",
    "        session_init=SmartInit(checkpoint_path),\n",
    "        model=M,\n",
    "        input_names=['x'],\n",
    "        output_names=['predict/y_pred']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1010 22:38:13 @collection.py:146]\u001b[0m New collections created in tower : tf.GraphKeys.MODEL_VARIABLES of size 10, tf.GraphKeys.METRIC_VARIABLES of size 2\n",
      "\u001b[32m[1010 22:38:13 @collection.py:165]\u001b[0m These collections were modified but restored in : (tf.GraphKeys.SUMMARIES: 0->7)\n",
      "\u001b[32m[1010 22:38:13 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step, optimize/beta1_power, optimize/beta2_power\n",
      "\u001b[32m[1010 22:38:14 @sessinit.py:114]\u001b[0m Restoring checkpoint from /home/nam/Dropbox/thesis/src/models/vae/train_log/train/model-8080 ...\n",
      "INFO:tensorflow:Restoring parameters from /home/nam/Dropbox/thesis/src/models/vae/train_log/train/model-8080\n"
     ]
    }
   ],
   "source": [
    "from tensorpack.predict import OfflinePredictor\n",
    "predictor = OfflinePredictor(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = get_default_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAE.load_data import *\n",
    "def get_data(hps):\n",
    "    dfX, df_next_deltaClose = load_data_seq(hps)\n",
    "\n",
    "    segment, next_segment, target_one_hot = segment_seq(dfX, df_next_deltaClose, hps)\n",
    "\n",
    "    train_segment, test_segment, _, _, train_target_one_hot, test_target_one_hot =\\\n",
    "    train_test_split(segment, next_segment, target_one_hot, hps)\n",
    "\n",
    "    return train_segment, train_target_one_hot, test_segment, test_target_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize: Z score\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = get_data(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15280, 60, 36)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15280, 1, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 60, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.TensorSpec((None, self.hps.T, self.hps.D), tf.float32, 'x'),\n",
    "M = hps.M\n",
    "N_val = X_val.shape[0]  # 2160\n",
    "y_preds = np.zeros([N_val,1, hps.C])\n",
    "y_preds[-1024:] = predictor(X_val[-1024:])[0]\n",
    "y_preds[:1024] = predictor(X_val[0:1024])[0]\n",
    "y_preds[1024:2048] = predictor(X_val[1024:2048])[0]\n",
    "y_preds = y_preds[:,0,:]\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aecf003af5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_preds, axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = hps.M\n",
    "N_train = X_train.shape[0]  # 2160\n",
    "y_train_hat = np.zeros([N_train, 1, hps.C])\n",
    "y_train_hat[-M:] = predictor(X_train[-M:])[0]\n",
    "\n",
    "for i in range(N_train // M):\n",
    "    idx = M * i\n",
    "    y_train_hat[M * i:M *(i+ 1)] = predictor(X_train[M * i:M *(i+ 1)])[0]\n",
    "    \n",
    "y_train_hat = np.argmax(y_train_hat[:,0,:], axis = -1)\n",
    "y_train_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def softmax(x):\n",
    "#     \"x shape is [N, Tau, C] when Tau == 1\"\n",
    "#     assert np.shape(x)[1] == 1, \"Tau is not 1\"\n",
    "#     x = np.squeeze(x, axis=(1,))\n",
    "#     e_x = np.exp(x - np.max(x, axis = -1, keepdims = True))\n",
    "#     return e_x / e_x.sum(axis = -1, keepdims = True)\n",
    "\n",
    "# print(softmax(outputs[0])[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Squeeze and argmax Target into 1d\n",
    "if len(y_val.shape) == 3:\n",
    "    y_val = np.argmax(y_val[:,0,:], axis=-1)\n",
    "    \n",
    "if len(y_train.shape) == 3:\n",
    "    y_train = np.argmax(y_train[:,0,:], axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traininng Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_train, y_train_hat)\n",
    "rp = classification_report(y_train, y_train_hat)\n",
    "score = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "print(cm)\n",
    "print(rp)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "rp = classification_report(y_val, y_pred)\n",
    "score = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(rp)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
